{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "[View Source Code](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) | [View Slides](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf) | [Watch Video Walkthrough](https://youtu.be/Z_ikDlimN6A?t=76)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSNK7duj5SeU"
      },
      "source": [
        "# 00. PyTorch Fundamentals\n",
        "\n",
        "The fundamentals are the _building blocks_ we are going to use throughout the rest of the course - Lego analogy again.\n",
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open source machine learning and deep learning framework.\n",
        "\n",
        "## What can PyTorch be used for?\n",
        "\n",
        "PyTorch allows you to manipulate and process data and write machine learning algorithms using Python code.\n",
        "\n",
        "## Who uses PyTorch?\n",
        "\n",
        "Many of the worlds largest technology companies such as [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla and Microsoft as well as artificial intelligence research companies such as [OpenAI use PyTorch](https://openai.com/blog/openai-pytorch/) to power research and bring machine learning to their products.\n",
        "\n",
        "![pytorch being used across industry and research](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
        "\n",
        "For example, Andrej Karpathy (head of AI at Tesla) has given several talks ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) about how Tesla use PyTorch to power their self-driving computer vision models.\n",
        "\n",
        "PyTorch is also used in other industries such as agriculture to [power computer vision on tractors](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
        "\n",
        "## Why use PyTorch?\n",
        "\n",
        "Machine learning researchers love using PyTorch. And as of February 2022, PyTorch is the [most used deep learning framework on Papers With Code](https://paperswithcode.com/trends), a website for tracking machine learning research papers and the code repositories attached with them.\n",
        "\n",
        "PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.\n",
        "\n",
        "So you can focus on manipulating data and writing algorithms and PyTorch will make sure it runs fast.\n",
        "\n",
        "And if companies such as Tesla and Meta (Facebook) use it to build models they deploy to power hundreds of applications, drive thousands of cars and deliver content to billions of people, it's clearly capable on the development front too.\n",
        "\n",
        "## What we're going to cover in this module\n",
        "\n",
        "This course is broken down into different sections (notebooks).\n",
        "\n",
        "Each notebook covers important ideas and concepts within PyTorch.\n",
        "\n",
        "Subsequent notebooks build upon knowledge from the previous one (numbering starts at 00, 01, 02 and goes to whatever it ends up going to).\n",
        "\n",
        "This notebook deals with the basic __building block__ of machine learning and _deep learning_, the tensor.\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **Introduction to tensors** | Tensors are the _basic building block_ of all of machine learning and deep learning. |\n",
        "| **Creating tensors** | Tensors can _represent almost any kind of data_ (images, words, tables of numbers). |\n",
        "| **Getting information from tensors** | If you can put information into a tensor, you'll want to get it out too. |\n",
        "| **Manipulating tensors** | Machine learning algorithms (like neural networks) involve _manipulating tensors_ in many different (mathematical) ways such as adding, multiplying, combining. |\n",
        "| **Dealing with tensor shapes** | One of the _most common issues_ in machine learning is dealing with _shape mismatches_ (trying to mixed wrong shaped tensors with other tensors). |\n",
        "| **Indexing on tensors** | If you've _indexed_ on a Python list or NumPy array, it's very similar with tensors, except they can have _far more dimensions_. |\n",
        "| **Mixing PyTorch tensors and NumPy** | PyTorch plays with _tensors_ ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy likes _arrays_ ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) sometimes you'll want to _mix and match_ these. |\n",
        "| **Reproducibility** | Machine learning is very _experimental_ and since it uses a lot of *randomness* to work, sometimes you'll want that *randomness* to not be so random. |\n",
        "| **Running tensors on GPU** | GPUs (Graphics Processing Units) make your code _run a lot faster_, PyTorch makes it _easy_ to run your code on GPUs. |\n",
        "\n",
        "## Where can you get help?\n",
        "\n",
        "All of the materials for this course [live on GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
        "\n",
        "And if you run into trouble, you can ask a question on the [Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions) there too.\n",
        "\n",
        "There's also the [PyTorch developer forums](https://discuss.pytorch.org/), a very helpful place for all things PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v3iRCRUTGeu"
      },
      "source": [
        "## Importing PyTorch\n",
        "\n",
        "> **Note:** Before running any of the code in this notebook, you should have gone through the [PyTorch setup steps](https://pytorch.org/get-started/locally/).\n",
        ">\n",
        "> However, **if you're running on Google Colab**, everything should work (Google Colab comes with PyTorch and other core Python libraries installed).\n",
        "\n",
        "Let's start by importing PyTorch and checking the version we're using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VxEOik46Y4i",
        "outputId": "bee5c39f-08c8-45f0-945c-4a79d7d7ea7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch has version: 2.0.1+cu118.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch_version = torch.__version__\n",
        "print(f'PyTorch has version: {torch_version}.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKIqOe_53OIl",
        "outputId": "1e3683c5-70f9-4a29-83cb-7fed35008419"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 19 00:00:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SqvI4S9TGew"
      },
      "source": [
        "Wonderful, it looks like we've got PyTorch 1.10.0+.\n",
        "\n",
        "This means if you're going through these materials, you'll see most compatability with PyTorch 1.10.0+, however if your version number is far higher than that, you might notice some inconsistencies.\n",
        "\n",
        "And if you do have any issues, please post on the course [GitHub Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-33BKR16iWc"
      },
      "source": [
        "## Introduction to tensors\n",
        "\n",
        "Now we've got PyTorch imported, it's time to learn about tensors.\n",
        "\n",
        "Tensors are the most _fundamental building block_ / _currency_ of machine learning, deep learning in particular.\n",
        "\n",
        "Their (Tensors') job is to _represent data_ in a __numerical__ way.\n",
        "\n",
        "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue - RGB), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "In _tensor-speak_ (the language used to describe tensors), the tensor would have three dimensions, one for `colour_channels`, `height` and `width`.\n",
        "\n",
        "But we're getting ahead of ourselves.\n",
        "\n",
        "Let's learn more about tensors by coding them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFF0N2TU7S7Q"
      },
      "source": [
        "### Creating tensors\n",
        "\n",
        "PyTorch loves tensors. So much so there's a whole documentation page dedicated to the [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) class.\n",
        "\n",
        "Your first piece of homework is to [read through the documentation on `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) for 10-minutes. But you can get to that later.\n",
        "\n",
        "Let's code.\n",
        "\n",
        "The first thing we're going to create is a **scalar**.\n",
        "\n",
        "A scalar is a (fancy name for) _single number_ and in _tensor-speak_ it's a _zero dimensional_ (0-d) tensor.\n",
        "\n",
        "> **Note:** That's a trend for this course. We'll focus on writing specific code. But often I'll set exercises which involve reading and getting familiar with the PyTorch documentation. Because after all, once you're finished this course, you'll no doubt want to learn more. And the documentation is somewhere you'll be finding yourself quite often."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUDgG2zk7Us5",
        "outputId": "7f43e7ba-f31c-4632-c644-f0a34606250e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(7), torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar, type(scalar) # `tensor` data type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqSuhW7rTGey"
      },
      "source": [
        "See how the above printed out `tensor(7)`?\n",
        "\n",
        "That means although `scalar` is a _single number_, it's of _type_ `torch.Tensor`.\n",
        "\n",
        "We can check the _dimensions_ of a tensor using the `ndim` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV98Yz868bav",
        "outputId": "e4c76f06-d07d-4770-e421-82bb22cce741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scalar.ndim # all scalars are 0-d tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO2YW_QGTGez"
      },
      "source": [
        "What if we wanted to _retrieve_ the number from the tensor?\n",
        "\n",
        "As in, turn it from `torch.Tensor` (type) to a Python integer (type)?\n",
        "\n",
        "To do we can use the `item()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4cyKumPfbE",
        "outputId": "867a1900-36d7-4699-9f97-ce8f9737b199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, int)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Get the Python number within a tensor (only works with one-element tensors, i.e. scalars)\n",
        "scalar.item(), type(scalar.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYs7ulrATGe0"
      },
      "source": [
        "Okay, now let's see a **vector**.\n",
        "\n",
        "A vector is a single dimensional (i.e. 1-d) tensor but can contain many numbers.\n",
        "\n",
        "As in, you could have a vector `[3, 2]` to describe `[bedrooms, bathrooms]` in your house. Or you could have `[3, 2, 2]` to describe `[bedrooms, bathrooms, car_parks]` in your house.\n",
        "\n",
        "The important trend here is that a vector is _flexible_ in what it can represent (the same with tensors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IZF6ASs8QH9",
        "outputId": "d28cbb5f-bc15-40d0-ea05-1aaa0a05e7a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7, 7]), torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector, type(vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXxRUUW2TGe1"
      },
      "source": [
        "Wonderful, `vector` now contains two 7's, my favourite number.\n",
        "\n",
        "How many dimensions do you think it'll have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03hm3VVv8kr4",
        "outputId": "38948e07-a098-416d-c1f0-1810e8e87a07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Check the number of dimensions of a vector\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0VYvSGbTGe1"
      },
      "source": [
        "Hmm, that's strange, `vector` contains two numbers but only has a _single_ dimension.\n",
        "\n",
        "I'll let you in on a trick.\n",
        "\n",
        "You can tell the number of dimensions a tensor in PyTorch has by the _number_ of _square brackets_ on the outside (`[`) and you only need to count _one_ side.\n",
        "\n",
        "How many square brackets does `vector` have?\n",
        "\n",
        "Another important concept for tensors is their `shape` attribute. The `shape` tells you how the _elements inside_ them are _arranged_.\n",
        "\n",
        "Let's check out the shape of `vector`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zREV1bDTGe2",
        "outputId": "ca733a12-c24d-49fe-fc09-5bfc3512ba0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Check shape of vector\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aWKppNyTGe2"
      },
      "source": [
        "The above returns `torch.Size([2])` which means our vector has a shape of `[2]`. This is because of the two elements we _placed inside_ the _square brackets_ (`[7, 7]`).\n",
        "\n",
        "Let's now see a **matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5iNwCYL8QO9",
        "outputId": "c38bff1a-280f-4202-de66-05db61f71ed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Matrix\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slicing\n",
        "MATRIX[0], MATRIX[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJUlXnjVYLtM",
        "outputId": "6d538130-4edd-455d-86d4-36b0d2f9427c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7, 8]), tensor([ 9, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3U1bCdjTGe3"
      },
      "source": [
        "Wow! More numbers! Matrices are as _flexible_ as vectors, except they've got an _extra dimension_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LREUbeb8r8j",
        "outputId": "ea28c8ba-cb1e-49c7-98b4-7899e0b8bc14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check number of dimensions\n",
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhXXgq-dTGe3"
      },
      "source": [
        "`MATRIX` has two dimensions (did you _count_ the _number_ of _square brakcets_ on the _outside_ of one side?).\n",
        "\n",
        "What `shape` do you think it will have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TL26I31TGe3",
        "outputId": "609a36ae-b724-4b97-cd40-a52274173b92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2]), torch.Size([2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Aliases\n",
        "MATRIX.shape, MATRIX.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLpUvrKTGe4"
      },
      "source": [
        "We get the output `torch.Size([2, 2])` because `MATRIX` is two elements _deep_ and two elements _wide_.\n",
        "\n",
        "How about we create a **tensor**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEMDQr188QWW",
        "outputId": "ce199da5-9b24-4a53-87c1-81d7d7a795b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJKkXD7TGe4"
      },
      "source": [
        "Woah! What a nice looking tensor.\n",
        "\n",
        "I want to __stress that__ _tensors_ can _represent almost anything_.\n",
        "\n",
        "The one we just created could be the sales numbers for a steak and almond butter store (two of my favourite foods).\n",
        "\n",
        "![a simple tensor in google sheets showing day of week, steak sales and almond butter sales](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
        "\n",
        "How many dimensions do you think it has? (hint: use the _square bracket counting trick_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dhuEsjS8QcT",
        "outputId": "fee83b07-76dd-448c-8f6e-9a436340059c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln9dys5VTGe4"
      },
      "source": [
        "And what about its shape?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdVv4iNRTGe5",
        "outputId": "f171c370-23f2-4d8b-bcd5-1421493eb7e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 3]), torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Check shape of TENSOR\n",
        "TENSOR.shape, TENSOR.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNBNRZSbb0k6",
        "outputId": "af67488f-9310-4604-efa5-f206ed90e360"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 6, 9],\n",
              "        [2, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxk8GU7oTGe5"
      },
      "source": [
        "Alright, it outputs `torch.Size([1, 3, 3])`.\n",
        "\n",
        "The dimensions go _outer to inner_.\n",
        "\n",
        "That means there's 1 dimension of 3 by 3.\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "> **Note:** You might've noticed me using lowercase letters for `scalar` and `vector` and uppercase letters for `MATRIX` and `TENSOR`. This was _on purpose_. _In practice_, you'll often see scalars and vectors denoted as lowercase letters such as `y` or `a`. And matrices and tensors denoted as uppercase letters such as `X` or `W`.\n",
        ">\n",
        "> You also might notice the names martrix and tensor used interchangably. This is common. Since in PyTorch you're often _dealing with_ `torch.Tensor`s (hence the tensor name), however, the shape and dimensions of what's inside will _dictate_ what it actually is.\n",
        "\n",
        "Let's summarise.\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dms7G4nkTGe5"
      },
      "source": [
        "### Random tensors\n",
        "\n",
        "We've established tensors _represent_ some form of data.\n",
        "\n",
        "And machine learning models such as neural networks _manipulate_ and _seek patterns within tensors_.\n",
        "\n",
        "But when building machine learning models with PyTorch, it's rare you'll create tensors _by hand_ (like what we've being doing).\n",
        "\n",
        "Instead, a machine learning model often _starts out_ with large _random_ tensors of numbers and _adjusts_ these random numbers as it _works through_ data to _better represent_ it.\n",
        "\n",
        "PA: This is essentially how order arise from chaos in Deep Learning.\n",
        "\n",
        "In essence:\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
        "\n",
        "As a data scientist, you can _define_ how the machine learning model starts (`initialization`), looks at data (`representation`) and updates (`optimization`) its _random_ numbers.\n",
        "\n",
        "We'll get hands on with these steps later on.\n",
        "\n",
        "For now, let's see how to create a tensor of _random_ numbers.\n",
        "\n",
        "We can do so using [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) and _passing_ in the `size` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJEtDx--GnK",
        "outputId": "20157aab-d967-4ad6-ade2-510d405b3611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.8191, 0.1959, 0.8271, 0.5044],\n",
              "         [0.2570, 0.6282, 0.7876, 0.0069],\n",
              "         [0.9606, 0.6722, 0.3272, 0.3850]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4)) # same as torch.rand(3, 4)\n",
        "random_tensor, random_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzEZl6XNiX3p",
        "outputId": "cd9f0e50-dd8b-422f-be2e-04e69f51f12b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB1c_cXTGe5"
      },
      "source": [
        "The _flexibility_ of `torch.rand()` is that we can _adjust_ the `size` to be whatever we want.\n",
        "\n",
        "For example, say you wanted a random tensor in the _common image_ `shape` of `[224, 224, 3]` (`[height, width, color_channels`], `[h, w, c]`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMF_NUp3Ym__",
        "outputId": "2910e4a4-b9c6-469b-c216-cf1b3f78b7f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, torch.Size([224, 224, 3]), torch.Size([224, 224, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Create a random tensor of size (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, colour channels (R, G, B)\n",
        "random_image_size_tensor.ndim, random_image_size_tensor.shape, random_image_size_tensor.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(size=(3, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKgaUnB3oTAh",
        "outputId": "8adda5ea-7d8f-4da4-f4b2-64533ae19225"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2372, 0.0448, 0.2815],\n",
              "        [0.9826, 0.9808, 0.4015],\n",
              "        [0.7535, 0.0364, 0.2251]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3, 3) # same as above without explicit reference to `size` param."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkzpzseqojFc",
        "outputId": "dfa82715-26b1-4e34-fa44-e53afe2eef37"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9154, 0.1899, 0.1073],\n",
              "        [0.6039, 0.2311, 0.7059],\n",
              "        [0.3716, 0.7596, 0.9467]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQNTY0eTGe6"
      },
      "source": [
        "### Zeros and ones\n",
        "\n",
        "Sometimes you'll just want to _fill_ tensors with zeros or ones.\n",
        "\n",
        "This happens a lot with _masking_ (like masking i.e. zeroing out some of the values in one tensor with zeros to let a model know _not_ to learn them).\n",
        "\n",
        "Let's create a tensor full of zeros with [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
        "\n",
        "Again, the `size` parameter _comes into play_. `.dtype` is the default data type of a tensor. Whenever a tensor is created in PyTorch, `torch.float32` is the default data type, unless it is explicitly defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzhd0hl9Vp6",
        "outputId": "3929e0be-484e-4444-91de-ecbb69057d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.Size([3, 4]),\n",
              " torch.Size([3, 4]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.shape, zeros.size(), zeros.dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros * random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSPXBwbBpWS4",
        "outputId": "07947dbb-42e9-4bd0-c97c-942084647b9a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQBZJRUZWTN"
      },
      "source": [
        "We can do the same to create a tensor of all ones except using [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html) instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRe6sSXiTGe6",
        "outputId": "5863ca50-6882-4a1c-db48-12c11df6f3ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.Size([3, 4]),\n",
              " torch.Size([3, 4]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.shape, ones.size(), ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hib1NYrSarL2"
      },
      "source": [
        "### Creating a range and tensors like\n",
        "\n",
        "Sometimes you might want a _range_ of numbers, such as 1 to 10 or 0 to 100.\n",
        "\n",
        "You can use `torch.arange(start, end, step)` to do so.\n",
        "\n",
        "Where:\n",
        "* `start` = start of range (e.g. 0)\n",
        "* `end` = end of range (e.g. 10)\n",
        "* `step` = how many steps in between each value (e.g. 1)\n",
        "\n",
        "> **Note:** In Python, you can use `range()` to create a range. However, in PyTorch, `torch.range()` is _deprecated_ and may show an error in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IqUs81d9W4W",
        "outputId": "846f6807-4fae-4144-a402-274b95fe4503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a404776195c1>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Use torch.arange(), torch.range() is deprecated\n",
        "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
        "\n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(1, 11, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knmvxcRhuFrD",
        "outputId": "7acb2436-c732-4f15-ca23-d855d0c6731f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(start=0, end=1000, step=77)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D6xXbcct8aH",
        "outputId": "b45fe133-a177-4d0c-ddf7-c7545ffacd1c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-bXf0Ugbh-D"
      },
      "source": [
        "Sometimes you might want one tensor of a certain type with the _same shape_ as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the _same shape_ as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones with the same shape as the `input` respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXwUut5BhHq",
        "outputId": "fcc0fd40-34d4-429f-c7f4-ed1ff15a04e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeroes = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeroes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also create a tensor of ones similar to another tensor\n",
        "ten_ones = torch.ones_like(input=zero_to_ten) # will have same shape\n",
        "ten_ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI0GVztYuoKT",
        "outputId": "771ae31b-2af6-4e24-f9c3-76712e35213b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Note:__ Tensor data types (`dtype`) is one of the 3 main sources of errors you'll run into with PyTorch & Deep Learning in general:\n",
        "\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device"
      ],
      "metadata": {
        "id": "rgFUH1Zuy-JP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huKZ6QlYTGe7"
      },
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Getting to know which is which can take some time.\n",
        "\n",
        "Generally, if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The _most common type_ (and generally the _default_) is `torch.float32` or `torch.float`.\n",
        "\n",
        "This is referred to as \"32-bit floating point\".\n",
        "\n",
        "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
        "\n",
        "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "Plus more!\n",
        "\n",
        "> **Note:** An integer is a _flat round number_ like `7` whereas a float has a _decimal_ `7.0`.\n",
        "\n",
        "The reason for all of these is to do with **precision in computing**.\n",
        "\n",
        "Precision is the _amount of detail_ used to _describe_ a number.\n",
        "\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but _sacrifice_ some performance on evaluation metrics like accuracy (faster to compute but less accurate), i.e. a genuine _tradeoff_.\n",
        "\n",
        "Single precision is 32-bit whereas half precision is 16-bit.\n",
        "\n",
        "> **Resources:**\n",
        "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
        "\n",
        "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3MoGnpw9XaF",
        "outputId": "962237bf-0882-46fe-84bf-b57a3dbff0af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "# Three of the most important parameters (`dtype`, `device`, `requires_grad`) when creating a tensor.\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded. Whether or not to track gradients with this tensor's operations\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.size(), float_32_tensor.dtype, float_32_tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhP8kzDfe_ty"
      },
      "source": [
        "Aside from `shape` issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are `datatype` and `device` issues.\n",
        "\n",
        "For example, one of tensors is `torch.float32` and the other is `torch.float16` (PyTorch often likes tensors to be the same format).\n",
        "\n",
        "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n",
        "\n",
        "We'll see more of this device talk later on and how to write __device-agnostic__ code.\n",
        "\n",
        "For now, let's create a tensor with `dtype=torch.float16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSuajld_09s",
        "outputId": "cb2462bd-936c-4c2c-9969-4c8399919a0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG3bkmhNgrFk",
        "outputId": "320e1032-3d0b-4847-f9f9-29d530ae4246"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor * float_32_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7JwWX0Ug4EZ",
        "outputId": "2e79d4d6-9a4f-4004-8f3f-0e2fa05bb1de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor, int_64_tensor = torch.tensor([3, 6, 9], dtype=torch.int32), torch.tensor([3, 6, 9], dtype=torch.int64)\n",
        "int_32_tensor.dtype, int_64_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixJAUG5RhN72",
        "outputId": "9dd610f9-c85f-4c09-a599-5e09525bc47b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.int32, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor * int_32_tensor * int_64_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho6oquB5hrNL",
        "outputId": "1eff9530-1b40-4966-9b34-27bbc9f8dc41"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 27., 216., 729.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjkB2AX7Upz"
      },
      "source": [
        "## Getting information from tensors (tensor attributes)\n",
        "\n",
        "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get/extract some information from them.\n",
        "\n",
        "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
        "* `shape` - what shape is the tensor? (some operations require _specific shape rules_)\n",
        "* `dtype` - what datatype are the _elements_ within the tensor stored in?\n",
        "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
        "\n",
        "Let's create a random tensor and find out details about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_X4D0j7Umq",
        "outputId": "fd93facc-ea49-4ef4-a5e4-2f9841ba62a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0130, 0.4957, 0.2827, 0.4532],\n",
            "        [0.2546, 0.7055, 0.0420, 0.4637],\n",
            "        [0.2575, 0.0042, 0.4260, 0.9293]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.shape` is a tensor attribute, written  without the parentheses whilst `.size()` is a function/method that has to be called with parentheses."
      ],
      "metadata": {
        "id": "k7sCHFKgkxac"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45K-E5uPg6cj"
      },
      "source": [
        "> **Note:** When you run into issues in PyTorch, it's very often one to do with one of the three _attributes_ above. So when the error messages show up, sing yourself a little song called \"what, what, where\":\n",
        "  * \"*what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdiWvoAi7UjL"
      },
      "source": [
        "## Manipulating tensors (tensor operations)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets _represented_ as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a _series_ of _operations_ (could be 1,000,000s+) on tensors to create a _representation_ of the _patterns_ in the input data.\n",
        "\n",
        "Neural networks are comprised of lots of mathematical operations that PyTorch code is going to run behind the scenes for us.\n",
        "\n",
        "These operations are often a _wonderful dance_ between:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication\n",
        "\n",
        "And that's it. Sure there are a few more here and there but these are the basic _building blocks_ of neural networks.\n",
        "\n",
        "__Stacking__ these _building blocks_ in the right way, you can create the most sophisticated of neural networks (just like __Lego__!).\n",
        "\n",
        "Deep Neural Networks are indeed the new Lego!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_6Dd7L7Uce"
      },
      "source": [
        "### Basic operations\n",
        "\n",
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`).\n",
        "\n",
        "They work just as you think they would."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X71WpQoPD7a4",
        "outputId": "efb6d3b2-6a54-4c88-b491-ac42fc573540"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4TlTWWEFeO",
        "outputId": "80c71c41-9443-40f9-8e47-dc0d04c9ce60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1VEHnuRkn8Q"
      },
      "source": [
        "Notice how the tensor values above didn't end up being `tensor([110, 120, 130])`, this is because the values inside the tensor don't change unless they're _reassigned_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuB1UjCIEJIA",
        "outputId": "8336eeb7-7f18-45f6-db08-c2a02ce15661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Tensors don't change unless reassigned\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYvqGpUTk1o6"
      },
      "source": [
        "Let's subtract a number and this time we'll reassign the `tensor` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4iWKoLsENry",
        "outputId": "69c55d98-dc7a-4365-e0a9-7f38529bae48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgZY-PaFNXa",
        "outputId": "699c1101-a45c-4aca-c47f-6706f11b469a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYXDoIOzk-6I"
      },
      "source": [
        "PyTorch also has a bunch of _built-in_ functions like [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (short for multiplication) and [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) to perform basic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVysdk3kFWbY",
        "outputId": "df8bf943-f3c2-4b86-ed2b-9493d471b1f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10, 20, 30]), tensor([20, 40, 60]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Can also use torch functions\n",
        "torch.multiply(tensor, 10), torch.mul(tensor, 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(tensor, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iobn-hjq8Ti",
        "outputId": "6c09d7e0-2d46-4b34-8e16-242471ce7a82"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxuPJIpNFbqO",
        "outputId": "67dbddb6-f753-42d7-9f11-ba86c04a9ac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Original tensor is still unchanged\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70UNL33AlVQq"
      },
      "source": [
        "However, it's more common to use the operator symbols like `*` instead of `torch.mul()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5v3RkR0F2Jq",
        "outputId": "39194ffe-24db-48d5-8a96-17ae5343bff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT5fVuyu7q5z"
      },
      "source": [
        "### Matrix multiplication (is all you need)\n",
        "\n",
        "One of the _most common operations_ in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "Matrix multiplication is sometimes referred to as the `dot product` (a __heavy dot__). These two are used _interchangeably_.\n",
        "\n",
        "PA: Matrix multiplication is the _workhorse_ that underpins the _meteoric rise_ of Deep Learning algorithms.\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
        "\n",
        "The TWO main rules for matrix multiplication to remember are:\n",
        "1. The **inner dimensions** must _match_:\n",
        "  * `(3, 2) @ (3, 2)` won't work\n",
        "  * `(2, 3) @ (3, 2)` will work\n",
        "  * `(3, 2) @ (2, 3)` will work\n",
        "2. The _resulting matrix_ has the _shape_ of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the _symbol_ for matrix multiplication.\n",
        "\n",
        "> **Resource:** You can see all of the rules for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
        "\n",
        "Let's create a tensor and perform element-wise multiplication and matrix multiplication on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7loucmDlEM",
        "outputId": "8a03f015-d4c2-415a-b704-7ec18fbfd044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape, tensor.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUAZ3_b0vOKv"
      },
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the _addition_ of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i42gkUeHvI_1",
        "outputId": "2683d6ac-4bc9-4523-a69f-169914165177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise matrix multiplication\n",
        "print(tensor, '*', tensor)\n",
        "print(f'Equals: {tensor * tensor}')\n",
        "# tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCBiiTTDk8y",
        "outputId": "bc91c365-5f95-40fd-d4e8-c4716e3ba988"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E_pROBDk2r",
        "outputId": "9b8beebc-65dc-419d-eaa4-bf6ac3809f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though NOT recommended.\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication by hand\n",
        "1*1 + 2*2 + 3*3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOS-X_x_7R0Y",
        "outputId": "a637710d-317e-4e73-c4df-42293508df4b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obbginUMv43A"
      },
      "source": [
        "You can do matrix multiplication by hand but it's not recommended.\n",
        "\n",
        "The in-built `torch.matmul()` method is faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qMSaLOoJscL",
        "outputId": "2c5a9e96-7d3e-42e8-f03b-062b98a9394b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.03 ms, sys: 3 s, total: 1.03 ms\n",
            "Wall time: 1.03 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand\n",
        "# Note: Avoid doing operations with for loops at all cost - they are extremely computationally expensive!\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i] # self-plus & reassignment\n",
        "value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWiKB0KwH74",
        "outputId": "107e5edf-97f0-4d06-c71b-c4c11e137299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 779 s, sys: 0 ns, total: 779 s\n",
            "Wall time: 738 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor) # Crux of matrix multiplication by PyTorch's vectorized version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUb7L3lu-amq",
        "outputId": "96e5f117-4332-44a4-9ab2-92f9666ee845"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 224 s, sys: 41 s, total: 265 s\n",
            "Wall time: 219 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looping through each of tensor's elements is quite cumbersome. So a lot of PyTorch functions/methods behind the scenes implement optimised versions of mathematical operations such as matrix multiplication.\n",
        "\n",
        "We should always try to use PyTorch's implementation of certain operations, except if they're basic ones like `+`, `*`. Chances are PyTorch's implemention is a lot faster."
      ],
      "metadata": {
        "id": "zGl_qInh_isv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3, 2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul17zyi3CevQ",
        "outputId": "83651475-440b-4058-ec6d-d60e712ab295"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.matmul(torch.rand(3, 2), torch.rand(3, 2))"
      ],
      "metadata": {
        "id": "g9vqfppjCjgQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below works\n",
        "torch.matmul(torch.rand(2, 3), torch.rand(3, 2)), torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV83Fkf7CwnB",
        "outputId": "d8fe2bcb-53e0-44c3-cf14-b9a8fd1ef554"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.6778, 0.5524],\n",
              "         [1.1867, 1.9467]]),\n",
              " tensor([[0.1716, 0.3240, 0.2135],\n",
              "         [0.6481, 0.8564, 0.4114],\n",
              "         [0.1955, 0.2115, 0.0738]]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.rand(3, 10), torch.rand(10, 3)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjU_j4P_DQBT",
        "outputId": "16871bcf-fc39-4db3-efa6-8506475c5d11"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ4DDmo1TGe-"
      },
      "source": [
        "## One of the most common errors in deep learning (`shape` errors)\n",
        "\n",
        "Because much of deep learning is _multiplying_ and _performing operations_ on matrices and matrices have a _strict rule_ about what `shapes` and `sizes` can be _combined_, one of the most common errors you'll run into in deep learning is `shape` mismatches."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fact that PyTorch also has `torch.mm` for matrix multiplication, a shorter version, shows literally how common matrix multiplications are in Deep Learning - they've made `torch.mm()` as an _alias_ for `torch.matmul()` so you can type four fewer characters, though `torch.matmul()` is far more self-explanatory."
      ],
      "metadata": {
        "id": "GXfByTPFEqq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "rN5RcoD4Jo6y"
      },
      "outputs": [],
      "source": [
        "# Shapes in matrix multiplication need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# Shape errors\n",
        "# torch.mm(tensor_A, tensor_B) # `torch.mm()` ~ `torch.matmul()` (it's an alias for writing less code)\n",
        "# torch.matmul(tensor_A, tensor_B) # (this will error)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A.shape, tensor_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEnsQcN-Gype",
        "outputId": "cff4c464-96d8-41e0-9d94-791ed65c91f1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNA6MZEFxWVt"
      },
      "source": [
        "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their _inner dimensions match_.\n",
        "\n",
        "One of the ways to do this is with a **transpose** (_switch_ the dimensions/axes of a given tensor).\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "* `torch.transpose(input, dim0, dim1)` - where `input` is the _desired tensor_ to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "* `tensor.T` - where `tensor` is the _desired tensor_ to transpose.\n",
        "\n",
        "Let's try the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUqgaANiy1wq",
        "outputId": "b91fc9ba-a9ef-4cda-f3a7-6f98621f4b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DveqxO7iy_Fi",
        "outputId": "1d416f16-7397-4e6a-be94-b4645f8c10f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason Daniel (author) spent so much time on matrix multiplication in PyTorch is MM one of the most common operations in Deep Learning."
      ],
      "metadata": {
        "id": "Gq4yqEX6rlPC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35rEIu-NKtVE",
        "outputId": "de765d92-6ece-43fe-a7fc-d58112a0cb88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfcFEqfLjN24"
      },
      "source": [
        "You can also use [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) which is a shorthand version for `torch.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3rJvW_TTGe_",
        "outputId": "e1cdfd7a-3109-40ad-865b-518abdfdf833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More work to be done to make below work ...\n",
        "# assert torch.matmul(tensor_A, tensor_B.T) == torch.mm(tensor_A, tensor_B.T), \"No way!\""
      ],
      "metadata": {
        "id": "7gj7uvgZsfR0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKozI4T0hFi"
      },
      "source": [
        "Without the transpose, the rules of matrix mulitplication aren't fulfilled and we get an error like above.\n",
        "\n",
        "How about a visual?\n",
        "\n",
        "![visual demo of matrix multiplication](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "You can create your own matrix multiplication visuals like this at http://matrixmultiplication.xyz/.\n",
        "\n",
        "> **Note:** A matrix multiplication like this is also _referred_ to as the [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA64Z4DmkB31"
      },
      "source": [
        "Neural networks are _full_ of matrix multiplications and dot products.\n",
        "\n",
        "The [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) module (we'll see this in action later on), also known as a _feed-forward layer_ or _fully connected layer_, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
        "\n",
        "$$\n",
        "y = x\\cdot{A^T} + b\n",
        "$$\n",
        "\n",
        "Where:\n",
        "* `x` is the input to the layer (deep learning is a _stack of layers_ like `torch.nn.Linear()` and others on top of each other).\n",
        "* `A` is the weights matrix created by the layer, this _starts out_ as _random_ numbers that get _adjusted_ as a neural network _learns to better represent patterns_ in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
        "  * **Note:** You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
        "* `b` is the _bias term_ used to _slightly offset_ the weights and inputs.\n",
        "* `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
        "\n",
        "This is a linear function (you may have seen something like $y = mx+b$ in high school or elsewhere), and can be used to draw a straight line!\n",
        "\n",
        "Let's play around with a linear layer.\n",
        "\n",
        "Try changing the values of `in_features` and `out_features` below and see what happens.\n",
        "\n",
        "Do you notice anything to do with the shapes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC_MjKW1LX7T",
        "outputId": "c58553a8-c630-4c8c-d694-5fb092bb0431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ],
      "source": [
        "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
        "torch.manual_seed(42)\n",
        "# This uses matrix multiplication\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input\n",
        "                         out_features=6) # out_features = describes outer value\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIGrP5j1pN7j"
      },
      "source": [
        "> **Question:** What happens if you change `in_features` from 2 to 3 above? Does it error? How could you change the shape of the input (`x`) to accomodate to the error? Hint: what did we have to do to `tensor_B` above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPNF0nMWoGEj"
      },
      "source": [
        "If you've never done it before, matrix multiplication can be a confusing topic at first.\n",
        "\n",
        "But after you've played around with it a few times and even cracked open a few neural networks, you'll notice it's everywhere.\n",
        "\n",
        "Remember, matrix multiplication is all you need.\n",
        "\n",
        "![matrix multiplication is all you need](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
        "\n",
        "*When you start digging into neural network layers and building your own, you'll find matrix multiplications everywhere. **Source:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjMmrJOOPv5e"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc of a tensor (aggregation)\n",
        "\n",
        "Now we've seen a few ways to manipulate tensors, let's run through a few ways to _aggregate_ them (go from more values to fewer values).\n",
        "\n",
        "First we'll create a tensor and then find the `max`, `min`, `mean` and `sum` of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFQbe5fP1Rk",
        "outputId": "e2ba89a8-73ed-4e7a-9af7-ee812f988603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x, x.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J-wfMdlsEco"
      },
      "source": [
        "Now let's perform some aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5wSP9YKP3Lb",
        "outputId": "3f49fa23-4ec6-4fe5-a66d-74dd013e1b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHoKpsg3sKQE"
      },
      "source": [
        "> **Note:** You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another _specific datatype_, otherwise the operation will fail.\n",
        "\n",
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cr23Y9uP3HO",
        "outputId": "c3aeee70-f696-4b98-ea46-f4b763ef5f33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below doesn't work\n",
        "# x.mean()\n",
        "# torch.mean(x)"
      ],
      "metadata": {
        "id": "IAzcvsd02V7K"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ApCaZjDkvp"
      },
      "source": [
        "### Positional min/max\n",
        "\n",
        "You can also find the _index_ of a tensor where the max or minimum _occurs_ with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful in case you just want the _position_ where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the [softmax activation function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzNBl9JSGlHi",
        "outputId": "a8dc91d3-3256-440f-e390-9c00f9e3098b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8, with maximum: 90\n",
            "Index where min value occurs: 0, with minimum: 10\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "# Find the position in a tensor that has the max/min value with `argmax()` and `argmin()` -> returns index position of target tensor where max/min value occurs\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}, with maximum: {tensor[tensor.argmax()]}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}, with minimum: {tensor[tensor.argmin()]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBu33WihOXBk"
      },
      "source": [
        "### Change tensor datatype\n",
        "\n",
        "As mentioned, a _common issue_ with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors.\n",
        "\n",
        "But there's a fix.\n",
        "\n",
        "You can change the datatypes of tensors using [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) where the `dtype` parameter is the datatype you'd like to use.\n",
        "\n",
        "First we'll create a tensor and check it's datatype (the _default_ is `torch.float32`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2FEsCAOaLu",
        "outputId": "80ff4880-2e1f-48ba-9f6a-9a3f6dd9d568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor, tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR30FHEc92of"
      },
      "source": [
        "Now we'll create another tensor the same as before but change its datatype to `torch.float16`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cac8gRYjOeab",
        "outputId": "f08e9493-c055-4dda-cd00-fdffd4cc45fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16),\n",
              " torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16, tensor_float16.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVlKJZ4-7_5"
      },
      "source": [
        "And we can do something similar to make a `torch.int8` tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yqovld2Oj6s",
        "outputId": "43fbb020-d004-411c-b2db-a73962a5e9cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8), torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Create a int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8, tensor_int8.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44GxVabar-xe"
      },
      "source": [
        "> **Note:** Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precisely a computer stores the value. And with a lower amount of _storage_, this generally results in _faster computation_ and a _smaller overall model_. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts. For more on this, I'd read up about [precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
        "\n",
        "> **Exercise:** So far we've covered a fair few tensor methods but there's a bunch more in the [`torch.Tensor` documentation](https://pytorch.org/docs/stable/tensors.html), I'd recommend spending 10-minutes scrolling through and looking into any that catch your eye. Click on them and then write them out in code yourself to see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkCtAYmGsHY"
      },
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing (tensors)\n",
        "\n",
        "Often times you'll want to `reshape` or change the dimensions of your tensors _without_ actually changing the values inside them. They help us fixing shape and/or dimension issues with our tensors.\n",
        "\n",
        "To do so, some _popular_ methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to a desired `shape` (if _compatible_), can also use `torch.Tensor.reshape()`. |\n",
        "| [`torch.Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a _view_ of the original tensor in a different `shape` but shares the same data (in memory) as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | _Concatenates_/_combine_ a sequence of `tensors` along a new dimension (`dim`)/axis (i.e. `vstack` or `hstack`), all `tensors` must be _same size_. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to _remove_ all the dimenions with _value_ `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions _permuted_ (_rearranged_/_swapped_) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are _all about manipulating tensors_ in some way. And because of the rules of matrix multiplication, if you've got shape mismatches (i.e. \\#1 issue in Deep Learning), you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n",
        "\n",
        "Let's try them out.\n",
        "\n",
        "First, we'll create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYjRTLOzG4Ev",
        "outputId": "0fd58897-0d44-4450-8d95-c800a81ce0a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape, x.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_VarMO9CoT8"
      },
      "source": [
        "Now let's add an extra dimension with `torch.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4WjpQ3SG-8",
        "outputId": "e61862d4-8674-45be-ca8c-3929602bd3e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.]]),\n",
              " torch.Size([7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Add an extra dimension, confirmed by the extra square bracket pair\n",
        "x_reshaped = x.reshape(7, 1) # (2, 7) or (7, 2) does not work because 2 * 7 > 7\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tig5xm0jCxuU"
      },
      "source": [
        "We can also change the view with `torch.view()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN2BNe5TGfB",
        "outputId": "130104bd-eaea-4136-e6e2-c42be46a8169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]),\n",
              " torch.Size([1, 7]),\n",
              " torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "# See more: https://stackoverflow.com/a/54507446/7900723\n",
        "# .view() is similar to .reshape() but shares the memory with the original tensor.\n",
        "z = x.view(1, 7)\n",
        "z, z.shape, z.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8joAaUEC2NX"
      },
      "source": [
        "Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the *same* tensor.\n",
        "\n",
        "So changing the view changes the original tensor too (i.e. view is a reference in memory to the underlying data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxURVvXTGfC",
        "outputId": "4a41efd6-ea2a-4e52-c48b-b78ecee554b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 7]),\n",
              " tensor([[5., 2., 3., 4., 5., 6., 7.]]),\n",
              " torch.Size([7]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z.shape, z, x.shape, x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxnqDBlpDDJ_"
      },
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX5Adf3ORiTK",
        "outputId": "8ee34fd7-aee6-466c-e24a-9098c728d041"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET56QzNHDuOI"
      },
      "source": [
        "How about removing _all_ _single_ dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()` (I remember this as *squeezing* the tensor to only have dimensions greater than 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Y2HEoDRxJZ",
        "outputId": "98fc7e6c-12ec-4c31-bca4-ae0eb441797b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.]])\n",
            "Previous tensor's shape: torch.Size([7, 1])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous tensor's shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped, i.e. redundant dim(s)\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\") # still the original values but with one pair square brackets removed\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acjDLk8WD8NC"
      },
      "source": [
        "And to do the _reverse_ of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUC-DEEwSYv7",
        "outputId": "1da423eb-d521-4032-a7e3-e50b1cebeec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previously squeezed tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Previous squeezed tensor's shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.]])\n",
            "New shape: torch.Size([7, 1])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previously squeezed tensor: {x_squeezed}\")\n",
        "print(f\"Previous squeezed tensor's shape: {x_squeezed.shape}\")\n",
        "\n",
        "## Add an extra dimension with unsqueeze\n",
        "# torch.unsqueeze() - adds a single dimension to a target tensor at a specified dim (dimension)\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9DuJzXgFbM5"
      },
      "source": [
        "You can also _rearrange_ the _order of axes_ values with `torch.permute(input, dims)`, where the `input` gets turned into a *view* with new `dims`.\n",
        "\n",
        "One of the common places to use `permute()` is with images. Deep Leaning needs to turn your data into numerical representations. `[height, width, colour_channel (RGB)]` is a quite common numerical representation of image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCRGCX8DTGfC",
        "outputId": "4e968f5d-2c41-424f-d66a-338604d6ac67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3)) # e.g. an image tensor with [height, width, colour_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis/dim order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 2->0, 0->1, 1->2; dimension values\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\") # [colour_channel, height, width]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0, 0, 0] = 42\n",
        "x_original[0, 0, 0], x_permuted[0, 0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUV0XA29tlYR",
        "outputId": "052bb7ce-5ea6-408b-a4c2-c85d62c9e6e9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(42.), tensor(42.))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LKaFemGBoE"
      },
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the _same data_ as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original. Once again, view tensors and their originals are linked by __reference__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEPqVL7fTGfC"
      },
      "source": [
        "## Indexing (selecting, slicing & dicing data from tensors)\n",
        "\n",
        "Sometimes you'll want to select _specific_ data from tensors (for example, only the first column or second row).\n",
        "\n",
        "To do so, you can use _indexing_.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy _arrays_ (as its main data type), indexing in PyTorch with tensors is very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXzdxCQTGfD",
        "outputId": "7c8e9bf3-fc2e-43d7-de81-74a2989fae08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape, x.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQG5krnKG43B"
      },
      "source": [
        "Indexing values goes _outer_ dimension -> _inner_ dimension (check out the _square brackets_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_Z3IAzTGfD",
        "outputId": "4f604464-edd0-4472-8cec-afae22affdc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\") # same as x[0, 0]\n",
        "print(f\"Third square bracket: {x[0][0][0]}\") # same as x[0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][1][1], x[0, 2, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQPRUl3VFU1W",
        "outputId": "fa15a06b-38ea-47ca-f6af-79bb16ad1b58"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5), tensor(9))"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLjaIFxHe89"
      },
      "source": [
        "You can also use `:` to specify \"all values in target dimension\" and then use a comma (`,`) to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCT09pqeTGfD",
        "outputId": "001ba3ae-da40-4788-f222-2d3e7f309e86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDx_gMsTGfD",
        "outputId": "13a67c3a-d365-4134-cd38-ea503aed4054"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiw3_1E3TGfD",
        "outputId": "7f451226-b9c3-4d60-bc47-348f76299701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5]), tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1], x[0, 1, 1] # Pay attention to the output difference, [] in particular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFVEgrKhTGfD",
        "outputId": "60b7d029-e1c6-4b83-9500-deeb2185b96a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :], x[0, 0] # same as x[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on x to return 9\n",
        "# Index on x to return 3, 6, 9\n",
        "x[0, 2, 2], x[:, :, 2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOluANIOLST_",
        "outputId": "d356aaa7-3f55-4ef1-a7b4-92a38425ae3d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), tensor([[3, 6, 9]]))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ik0r11RIxtm"
      },
      "source": [
        "Indexing can be quite confusing to begin with, especially with larger tensors (I still have to try indexing multiple times to get it right). But with a bit of practice and following the data explorer's motto (***visualize, visualize, visualize***), you'll start to get the hang of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZaW0Bq7rCm"
      },
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a _popular_ Python _numerical computing library_, PyTorch has functionality to _interact_ with it nicely.  \n",
        "\n",
        "The _two main methods_ you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
        "\n",
        "Let's try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDrDCnvY7rKS",
        "outputId": "967c7f0d-2219-47b7-d424-69dc89b372ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'),\n",
              " array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " torch.float64,\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0) # note the parameters as float not int\n",
        "tensor = torch.from_numpy(array) # warning: when converting from numpy -> pytorch, pytorch relfects numpy's default datatype of float64 unless specified otherwise\n",
        "\n",
        "array.dtype, array, tensor.dtype, tensor, tensor.type(torch.float32).dtype"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(1.0, 7.0).dtype, torch.arange(1, 7).dtype,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMpewxmOKeDe",
        "outputId": "7b3d4650-d702-4bcd-da05-01166fe6d48c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16JG6cONLPnO"
      },
      "source": [
        "> **Note:** By _default_, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
        "\n",
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwl7VCREv8L",
        "outputId": "28124d18-92a9-4b84-8c53-d9f624b4fdf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'),\n",
              " array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " torch.float64,\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Change the array, keep the tensor\n",
        "array = array + 1 # Change the value of `array`, what will this do to `tensor`?\n",
        "array.dtype, array, tensor.dtype, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVvu1p0MTWc"
      },
      "source": [
        "And if you want to go from PyTorch tensor to NumPy array, you can call `tensor.numpy()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw_7ZyVaTKxQ",
        "outputId": "75ff91c7-7038-48d3-fa15-f9785a83fd45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32,\n",
              " tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " dtype('float32'),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor.dtype, tensor, numpy_tensor.dtype, numpy_tensor,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt8yEV1jMfi2"
      },
      "source": [
        "And the same rule applies as above, if you change the original `tensor`, the new `numpy_tensor` stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMp6ZSkET4_Y",
        "outputId": "241767a7-ff8d-4340-a26d-5963acb4488c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Change the tensor, keep the array the same - this means they don't share memory.\n",
        "tensor = tensor + 1 # what happens to `numpy_tensor`?\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because Numpy is so prevalent, PyTorch and Numpy work pretty well together."
      ],
      "metadata": {
        "id": "6GjpeOcRS6_2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gU3ubCrUkI-"
      },
      "source": [
        "## Reproducibility (trying to take the randomness out of random)\n",
        "\n",
        "We've touched upon the concept of neural networks _harnessing_ the power of randomness. As you learn more about neural networks and machine learning, you'll start to discover how much _randomness_ plays a part.\n",
        "\n",
        "Well, __pseudorandomness__ (generated randomness) that is. Because after all, as they're _designed_, a computer is __fundamentally deterministic__ (each step is _predictable_) so the randomness they create are _simulated_ randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
        "\n",
        "How does this relate to neural networks and deep learning then?\n",
        "\n",
        "We've discussed neural networks _start with random numbers_ to _describe patterns_ in data (these numbers are _poor descriptions_) and try to _improve_ those random numbers _using tensor operations_ (and a few other things we haven't discussed yet) to _better describe patterns_ in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "``start with random numbers -> tensor operations -> try to make better (again and again and again...)``\n",
        "\n",
        "Although randomness is nice and _powerful_, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform _repeatable_ experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where **reproducibility** comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwxnwEbTGfF",
        "outputId": "1e52045e-8c7a-4c71-a3c4-efdff1106748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]]), torch.float32\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]]), torch.float32\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}, {random_tensor_A.dtype}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}, {random_tensor_B.dtype}\\n\")\n",
        "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
        "\n",
        "# Comparison operator to compare values in two tensors\n",
        "random_tensor_A == random_tensor_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPU6mDKJnr8M"
      },
      "source": [
        "Just as you might've expected, the tensors come out with different values each time the cell is run.\n",
        "\n",
        "But what if you wanted to created two random tensors with the *same* values.\n",
        "\n",
        "As in, the tensors would still contain random values but they would be of the same _flavour_.\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that \"__flavours__\" the randomness.\n",
        "\n",
        "PA: Daniel likes to use `42` because it's the answer to the Universe.\n",
        "\n",
        "Let's try it out by creating some more *flavoured* random tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB6d1GfYTGfF",
        "outputId": "d18e7b83-2ce8-4cc4-ec79-cd6b31a775fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# Set the random seed\n",
        "RANDOM_SEED = 42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called\n",
        "# Without this, tensor_D would be different to tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "\n",
        "random_tensor_C == random_tensor_D # comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uct53Xr5QRC_"
      },
      "source": [
        "Nice!\n",
        "\n",
        "It looks like setting the seed worked.\n",
        "\n",
        "> **Resource:** What we've just covered only scratches the surface of reproducibility in PyTorch. For more, on reproducbility in general and random seeds, I'd checkout:\n",
        "> * [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html) (a good exericse would be to read through this for 10-minutes and even if you don't understand it now, being aware of it is important).\n",
        "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (this'll give a good overview of random seeds and pseudorandomness in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIIM7t27rQ-"
      },
      "source": [
        "## Running tensors on GPUs (to significantly speed up computations)\n",
        "\n",
        "Deep learning algorithms require/involve a lot of _numerical_ operations/computations (literally crunching numbers).\n",
        "\n",
        "And by default, these operations are often done on a CPU (Central Processing Unit).\n",
        "\n",
        "However, there's another _common piece_ of _hardware_ called a GPU (Graphics Processing Unit), which is often much faster at performing the _specific types_ of _operations_ that neural networks require (i.e. matrix multiplications) than CPUs.\n",
        "\n",
        "Your computer might have one.\n",
        "\n",
        "If so, you should look to use it _whenever_ you can to train neural networks because chances are it'll speed up the training time _dramatically_.\n",
        "\n",
        "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n",
        "\n",
        "> **Note:** When I refer to \"GPU\" throughout this course, I'm refering to a [Nvidia GPU with CUDA](https://developer.nvidia.com/cuda-gpus) enabled (CUDA is a _computing platform_ and API that allow GPUs be used/employed for _general purpose computing_ & not just graphics) unless otherwise specified."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs = Faster computation on numbers, thanks to NVIDIA hardware + Compute Unified Device Architecture (CUDA) + PyTorch working behind the scenes to make everything hunky dory (good)."
      ],
      "metadata": {
        "id": "ChuW0qJbKDiW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UiR6QpoYQH_"
      },
      "source": [
        "\n",
        "### 1. Getting a GPU\n",
        "\n",
        "You may already know what's going on when I say GPU. But if not, there are a few ways to get access to one.\n",
        "\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "There are more options for using GPUs but the above three will _suffice_ for now.\n",
        "\n",
        "Personally, I use a _combination_ of Google Colab and my own personal computer for _small scale experiments_ (and creating this course) and go to cloud resources when I need more compute power.\n",
        "\n",
        "PyTorch + GPU Drivers (i.e. CUDA) takes a little bit of setting up.\n",
        "\n",
        "> **Resource:** If you're looking to purchase a GPU of your own but not sure what to get, [Tim Dettmers has an _excellent guide_](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called _bang_) means \"run this on the command line\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEMcO-9zYc-w",
        "outputId": "f93e5759-a4db-4d56-c503-7027c7a6e388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 19 00:10:32 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvkB9p5zYf8E"
      },
      "source": [
        "If you don't have a Nvidia GPU accessible, the above will output something like:\n",
        "\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
        "```\n",
        "\n",
        "In that case, go back up and follow the install steps.\n",
        "\n",
        "If you do have a GPU, the line above will output something like:\n",
        "\n",
        "```\n",
        "Wed Jan 19 22:09:08 2022       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvibZ6e0YcDk"
      },
      "source": [
        "\n",
        "\n",
        "### 2. Getting PyTorch to run on the GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step is getting PyTorch to use for _storing data_ (`tensors`) and _computing_ on data (_performing operations on tensors_).\n",
        "\n",
        "PA: Tensor is the only true __currency__ of Deep Learning!\n",
        "\n",
        "To do so, you can use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "Rather than talk about it, let's try it out.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweDLgwjEvZ2",
        "outputId": "d9b0a002-177e-47ec-b712-9e6fd5f403da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jedZcx2PZFpL"
      },
      "source": [
        "If the above outputs `True`, PyTorch can _see_ and _use_ the device (GPU), if it outputs `False`, it can't see the GPU and in that case, you'll have to go back through the installation steps.\n",
        "\n",
        "Now, let's say you wanted to set up your code so it runs on CPU *or* the GPU if it was available.\n",
        "\n",
        "That way, if you or someone decides to run your code, it'll work _regardless_ of the computing device they're using.\n",
        "\n",
        "Let's create a `device` variable to store what kind of device is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j92HBCKB7rYa",
        "outputId": "398284ae-516d-4bcc-a88b-7fe1ec05c3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFyPP2WaCch"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA _device_ (a GPU) and if it output `\"cpu\"`, our PyTorch code will _stick with_ the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's _best practice_ to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do *much* faster computing, you can use _multiple_ GPUs.\n",
        "\n",
        "You can _count_ the number of GPUs PyTorch has _access_ to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArsn0DFTGfG",
        "outputId": "9704ede4-965c-4bdb-fbef-3d1b623f2a2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNf1hiqa-gO"
      },
      "source": [
        "Knowing the number of GPUs PyTorch has access to is helpful in case you want to run a _specific process_ on one GPU and another process on another (PyTorch also has features to let you run a process across *all* GPUs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQLcuj68OA-"
      },
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "You can put tensors (and models, we'll see this later) on a _specific device_ by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the _target device_ you'd like the tensor (or model) to go to and reside.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster _numerical computing_ than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU. So this setup is fault tolerant to a large degree.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) _returns_ a _copy_ of that tensor, e.g. the same tensor will be on CPU and GPU. To __overwrite__ tensors, `reassign` them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhI3srFXEHfP",
        "outputId": "11d8714b-0300-42c5-ccc9-5677d29d0b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3], device='cuda:0'), device(type='cuda', index=0))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3], device='cpu') # by default, device is cpu\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu, tensor_on_gpu.device # explicit device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXeRKO0TGfG"
      },
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (devices like GPUs are __0-indexed__, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` _respectively_, up to `'cuda:n'`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puyUX4Bci5D"
      },
      "source": [
        "### 4. Moving tensors back to the CPU\n",
        "\n",
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU and only works in CPUs).\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "3ChSLJgPTGfG",
        "outputId": "c0629704-b08e-4971-9460-d39608c88403"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-818c70e356e8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform/convert it to NumPy n-dim array (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform/convert it to NumPy n-dim array (this will error)\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhymtkRDTGfG"
      },
      "source": [
        "Instead, to get a tensor back to CPU and usable/compatible with NumPy we can use [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
        "\n",
        "This command copies the tensor to CPU _memory_ first so it's usable with CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN15s-NdTGfG",
        "outputId": "9d98fbc7-80de-4ada-bfe7-11723b66499a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), dtype('int64'))"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu, tensor_back_on_cpu.dtype # tensor_back_on_cpu.device errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzNH5lrTGfH"
      },
      "source": [
        "The above _returns_ a __copy__ of the GPU tensor in CPU _memory_ so the original tensor is still on GPU and intact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5u83PCRTGfH",
        "outputId": "3a4fb3b9-ed5c-4342-b141-433309d381fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmBpnuPTGfH"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "All of the exercises are focused on practicing the code above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "**Resources:**\n",
        "\n",
        "* [Exercise template notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
        "* [Example solutions notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (try the exercises *before* looking at this).\n",
        "\n",
        "1. Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) and for [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "2. Create a random tensor with shape `(7, 7)`.\n",
        "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor).\n",
        "4. Set the random seed to `0` and do exercises 2 & 3 over again.\n",
        "5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one). If there is, set the GPU random seed to `1234`.\n",
        "6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed).\n",
        "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "8. Find the maximum and minimum values of the output of 7.\n",
        "9. Find the maximum and minimum index values of the output of 7.\n",
        "10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDnaQRNtJvjm"
      },
      "source": [
        "## Extra-curriculum\n",
        "\n",
        "* Spend 1-hour going through the [PyTorch basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) (I'd recommend the [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) sections).\n",
        "* To learn more on how a tensor can represent data, see this video: [What's a tensor?](https://youtu.be/f5liqUk0ZTw)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xlmBpnuPTGfH",
        "NDnaQRNtJvjm"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "interpreter": {
      "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}